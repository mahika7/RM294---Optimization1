{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "GUROBI_TIME_LIMIT = 432"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Gurobi vs Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Name | EID |\n",
    "| --- | --- |\n",
    "| Palak Agarwal| pa9797 |\n",
    "| Mahika Bansal| mh62835 |\n",
    "| Brandt Green | bwg537 |\n",
    "| Chandler Wrenn | clw4642 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns; sns.set_theme()\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import linear_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "# Set a random seed so that we can get consistent shuffling for each run. Helpful for debuggin purposes.\n",
    "np.random.seed(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the the training and testing data and insert a new column in the beginning labeled 'X0' which will consist of all $1$s that will act as our intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X41</th>\n",
       "      <th>X42</th>\n",
       "      <th>X43</th>\n",
       "      <th>X44</th>\n",
       "      <th>X45</th>\n",
       "      <th>X46</th>\n",
       "      <th>X47</th>\n",
       "      <th>X48</th>\n",
       "      <th>X49</th>\n",
       "      <th>X50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.53615</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.53541</td>\n",
       "      <td>0.71889</td>\n",
       "      <td>-2.09915</td>\n",
       "      <td>-0.44284</td>\n",
       "      <td>-0.59898</td>\n",
       "      <td>-1.64257</td>\n",
       "      <td>0.20776</td>\n",
       "      <td>0.76064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.36187</td>\n",
       "      <td>1.79310</td>\n",
       "      <td>-0.63129</td>\n",
       "      <td>-0.06175</td>\n",
       "      <td>0.51105</td>\n",
       "      <td>0.48875</td>\n",
       "      <td>-0.61277</td>\n",
       "      <td>-0.47105</td>\n",
       "      <td>-1.13978</td>\n",
       "      <td>-0.26077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.80834</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.73461</td>\n",
       "      <td>0.55198</td>\n",
       "      <td>-2.14767</td>\n",
       "      <td>-1.55294</td>\n",
       "      <td>1.51491</td>\n",
       "      <td>-1.14397</td>\n",
       "      <td>0.73759</td>\n",
       "      <td>1.32124</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.67798</td>\n",
       "      <td>-0.16568</td>\n",
       "      <td>0.06540</td>\n",
       "      <td>0.13716</td>\n",
       "      <td>1.25820</td>\n",
       "      <td>-0.12083</td>\n",
       "      <td>-1.56483</td>\n",
       "      <td>-0.24256</td>\n",
       "      <td>-0.00183</td>\n",
       "      <td>1.18745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.53043</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.09726</td>\n",
       "      <td>0.10763</td>\n",
       "      <td>-0.19422</td>\n",
       "      <td>0.33545</td>\n",
       "      <td>-0.40820</td>\n",
       "      <td>0.13326</td>\n",
       "      <td>0.70618</td>\n",
       "      <td>0.39497</td>\n",
       "      <td>...</td>\n",
       "      <td>1.10880</td>\n",
       "      <td>0.33379</td>\n",
       "      <td>0.28205</td>\n",
       "      <td>-1.08629</td>\n",
       "      <td>-0.11535</td>\n",
       "      <td>0.25786</td>\n",
       "      <td>-0.08884</td>\n",
       "      <td>-0.75123</td>\n",
       "      <td>1.45061</td>\n",
       "      <td>0.29059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.42824</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.06770</td>\n",
       "      <td>0.55784</td>\n",
       "      <td>0.70085</td>\n",
       "      <td>-1.12138</td>\n",
       "      <td>1.72227</td>\n",
       "      <td>0.61353</td>\n",
       "      <td>0.70091</td>\n",
       "      <td>-0.41798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.69251</td>\n",
       "      <td>-0.35099</td>\n",
       "      <td>0.62456</td>\n",
       "      <td>0.43452</td>\n",
       "      <td>-0.36741</td>\n",
       "      <td>-1.14468</td>\n",
       "      <td>-0.13652</td>\n",
       "      <td>-0.55721</td>\n",
       "      <td>0.41630</td>\n",
       "      <td>0.48449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.56669</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.48873</td>\n",
       "      <td>0.21148</td>\n",
       "      <td>0.56839</td>\n",
       "      <td>0.64684</td>\n",
       "      <td>0.16387</td>\n",
       "      <td>-0.00215</td>\n",
       "      <td>0.12514</td>\n",
       "      <td>0.49357</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00060</td>\n",
       "      <td>1.07528</td>\n",
       "      <td>0.18228</td>\n",
       "      <td>-1.13846</td>\n",
       "      <td>0.10609</td>\n",
       "      <td>0.54464</td>\n",
       "      <td>-0.38349</td>\n",
       "      <td>-0.42577</td>\n",
       "      <td>2.66765</td>\n",
       "      <td>-0.05075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         y      X0       X1      X2       X3       X4       X5       X6  \\\n",
       "0  8.53615 1.00000 -1.53541 0.71889 -2.09915 -0.44284 -0.59898 -1.64257   \n",
       "1  4.80834 1.00000 -1.73461 0.55198 -2.14767 -1.55294  1.51491 -1.14397   \n",
       "2 -1.53043 1.00000  0.09726 0.10763 -0.19422  0.33545 -0.40820  0.13326   \n",
       "3 -0.42824 1.00000 -0.06770 0.55784  0.70085 -1.12138  1.72227  0.61353   \n",
       "4  0.56669 1.00000  0.48873 0.21148  0.56839  0.64684  0.16387 -0.00215   \n",
       "\n",
       "       X7       X8  ...      X41      X42      X43      X44      X45      X46  \\\n",
       "0 0.20776  0.76064  ...  0.36187  1.79310 -0.63129 -0.06175  0.51105  0.48875   \n",
       "1 0.73759  1.32124  ... -0.67798 -0.16568  0.06540  0.13716  1.25820 -0.12083   \n",
       "2 0.70618  0.39497  ...  1.10880  0.33379  0.28205 -1.08629 -0.11535  0.25786   \n",
       "3 0.70091 -0.41798  ...  0.69251 -0.35099  0.62456  0.43452 -0.36741 -1.14468   \n",
       "4 0.12514  0.49357  ... -0.00060  1.07528  0.18228 -1.13846  0.10609  0.54464   \n",
       "\n",
       "       X47      X48      X49      X50  \n",
       "0 -0.61277 -0.47105 -1.13978 -0.26077  \n",
       "1 -1.56483 -0.24256 -0.00183  1.18745  \n",
       "2 -0.08884 -0.75123  1.45061  0.29059  \n",
       "3 -0.13652 -0.55721  0.41630  0.48449  \n",
       "4 -0.38349 -0.42577  2.66765 -0.05075  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('training_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# We separate out a set of the orginal data here before messing with anything because we will want to feed it just like this into scikit learn much later on.\n",
    "X_train_og, y_train_og = train_data.drop(columns='y').to_numpy(), train_data['y'].to_numpy()\n",
    "\n",
    "train_df = train_data.copy()\n",
    "train_df.insert(1,column='X0',value=np.ones(len(train_data)))\n",
    "\n",
    "test_df =test_data.copy()\n",
    "test_df.insert(1,column='X0',value=np.ones(len(test_data)))\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of shuffled indices from the training data and use the indices to create a new, shuffled training df\n",
    "shuffled_indices = np.random.permutation(train_df.index)\n",
    "shuffled_train_df = train_df.iloc[shuffled_indices]\n",
    "\n",
    "# Separate out the X and y variables from the training and test sets. Also, convert them to numpy arrays.\n",
    "X_train, y_train = shuffled_train_df.drop(columns='y').to_numpy(), shuffled_train_df['y'].to_numpy()\n",
    "X_test, y_test = test_df.drop(columns='y').to_numpy(), test_df['y'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is shuffled, we need to get our k_fold indices. We can use sklearns Kfold function because it helps us abstract away some of the annoying complexities, such as how to handle distributing the data points to folds when the data is not perfectly divisible by the number of folds. \n",
    "\n",
    "The KFolds class is a generator that will iteratively yield the training and testing indices of each k-fold in a tuple. In the below cell, we loop through each fold and we put all of the indices in a dictionary, which seems like too much effort and extra complexity for now, but it will make our code later on much more readable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_indices': array([ 25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,\n",
      "        38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,\n",
      "        51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
      "        77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,\n",
      "        90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
      "       103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
      "       116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
      "       129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
      "       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
      "       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "       168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180,\n",
      "       181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193,\n",
      "       194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206,\n",
      "       207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "       220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n",
      "       233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245,\n",
      "       246, 247, 248, 249]), 'test_indices': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24])}\n"
     ]
    }
   ],
   "source": [
    "num_of_k_folds = 10\n",
    "split_indices = KFold(n_splits=num_of_k_folds).split(X_train)\n",
    "\n",
    "k_folds_dict:dict = {}\n",
    "for i, indices in enumerate(split_indices):\n",
    "    index_dict = {}\n",
    "    # The training indices are in the first item of the tuple and the testing indices are in the second.\n",
    "    index_dict['train_indices'] = indices[0]\n",
    "    index_dict['test_indices'] = indices[1]\n",
    "    k_folds_dict[i] = index_dict\n",
    "\n",
    "# Sample of the dicitionary printed for the first fold\n",
    "print(k_folds_dict[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking the optimal K with Gurobi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "      <th>35</th>\n",
       "      <th>40</th>\n",
       "      <th>45</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    5    10   15   20   25   30   35   40   45   50\n",
       "0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "5  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "6  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "7  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "8  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "9  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe to store the cross validation results for the gurobi optimization\n",
    "# We will be updating this later on in our Gurobi loop\n",
    "\n",
    "k_options = np.arange(5,51,5)\n",
    "\n",
    "gurobi_results_df = pd.DataFrame(index=k_folds_dict.keys(),columns=k_options)\n",
    "gurobi_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some basic parameters that we will need later on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 50 # Make sure this number is big enough!! M of like 200ish doesn't work. So be wary\n",
    "\n",
    "# Number of independent variables in our problem. This will not include the intercept term\n",
    "beta_num = X_train.shape[1] - 1\n",
    "\n",
    "# The betas are continuous, but the z variables will be binary\n",
    "v_type = ['C']*(beta_num+1) + ['B']*beta_num\n",
    "\n",
    "# Betas can be negative in this problem. But the z variables are binary 1/0\n",
    "lower_bounds = [-M]*(beta_num+1) + [0]*beta_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_gurobi(X,y,k):\n",
    "    \"\"\"Returns an array of the 51 beta coefficients  which are optimal betas, solved with gurobi.\n",
    "    Inputs: X and y data as numpy arrays. And the k value.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the matrices for the quadratic and linear objective functions\n",
    "    quadratic_obj = np.zeros(shape=(2*beta_num+1,2*beta_num+1))\n",
    "    quadratic_obj[:(beta_num+1),:(beta_num+1)] = X.T @ X\n",
    "\n",
    "    linear_obj = np.zeros(shape=beta_num*2+1)\n",
    "    linear_obj[:(beta_num+1)] = -2*y.T @ X\n",
    "\n",
    "\n",
    "    # Now we can fill in the equations for gurobi\n",
    "    sense = []\n",
    "    b = []\n",
    "\n",
    "    # We need two big M constraints for each beta and 1 constraint to make sure beta number = k \n",
    "    num_constraints = beta_num * 2 + 1\n",
    "    A = np.zeros(shape=(num_constraints,len(linear_obj)))\n",
    "\n",
    "\n",
    "    # Constraint that the number of independent betas should sum to <= k. Excludes the intercept beta.\n",
    "    A[0,(beta_num+1):] = 1\n",
    "    sense.append('<')\n",
    "    b.append(k)\n",
    "\n",
    "    # Add the big M constraints\n",
    "    # Skip the intercept term \n",
    "    # Start on row index 1 (because 0 is set above)\n",
    "    row_index = 1\n",
    "    for i in range(1,beta_num+1):\n",
    "        # Set constraint that beta must be less than M\n",
    "        A[row_index,i] = 1\n",
    "        A[row_index, i + beta_num] = -M\n",
    "        sense.append('<')\n",
    "        b.append(0)\n",
    "        row_index += 1\n",
    "\n",
    "        # Set constraint that beta must be greater than -M\n",
    "        A[row_index,i] = 1\n",
    "        A[row_index, i + beta_num] = M\n",
    "        sense.append('>')\n",
    "        b.append(0)\n",
    "\n",
    "        row_index += 1\n",
    "\n",
    "    # Now put the equations into Gurobi and solve!\n",
    "    regression_mod = gp.Model()\n",
    "    # Important to set the lower bound here because otherwise Gurobi will default to 0.\n",
    "    regression_mod_x = regression_mod.addMVar(len(linear_obj), lb=lower_bounds, vtype=v_type)\n",
    "    portMod_con = regression_mod.addMConstrs(A, regression_mod_x, sense, b)\n",
    "    regression_mod.setMObjective(quadratic_obj,linear_obj,0,sense=gp.GRB.MINIMIZE)\n",
    "\n",
    "    regression_mod.Params.OutputFlag = 0 \n",
    "    regression_mod.Params.TimeLimit = GUROBI_TIME_LIMIT\n",
    "    regression_mod.optimize()\n",
    "\n",
    "    # Return all of the betas as the results!!\n",
    "    return regression_mod_x.x[:(beta_num+1)]\n",
    "\n",
    "# pd.DataFrame(solve_gurobi(X_train,y_train,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we, just define two helper functions for evaluating the results of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_y(X, betas):\n",
    "    \"\"\"Outputs the predicted y values\"\"\"\n",
    "    return X @ betas\n",
    "\n",
    "def sse(y_true, y_predict):\n",
    "    \"\"\"Returns the sum of squared errors.\"\"\"\n",
    "    return sum((y_true - y_predict)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "      <th>35</th>\n",
       "      <th>40</th>\n",
       "      <th>45</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121.08483</td>\n",
       "      <td>83.22601</td>\n",
       "      <td>84.98515</td>\n",
       "      <td>82.43595</td>\n",
       "      <td>87.58834</td>\n",
       "      <td>95.66110</td>\n",
       "      <td>97.65884</td>\n",
       "      <td>97.40345</td>\n",
       "      <td>96.66076</td>\n",
       "      <td>97.57031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.27096</td>\n",
       "      <td>68.72295</td>\n",
       "      <td>85.44507</td>\n",
       "      <td>91.70347</td>\n",
       "      <td>87.32364</td>\n",
       "      <td>95.86751</td>\n",
       "      <td>96.42208</td>\n",
       "      <td>96.91586</td>\n",
       "      <td>100.55214</td>\n",
       "      <td>101.13772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.40846</td>\n",
       "      <td>62.50184</td>\n",
       "      <td>70.91066</td>\n",
       "      <td>83.65107</td>\n",
       "      <td>75.81232</td>\n",
       "      <td>73.46238</td>\n",
       "      <td>78.72707</td>\n",
       "      <td>80.83133</td>\n",
       "      <td>79.28233</td>\n",
       "      <td>79.96562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72.64028</td>\n",
       "      <td>62.72359</td>\n",
       "      <td>71.70770</td>\n",
       "      <td>71.71293</td>\n",
       "      <td>70.69936</td>\n",
       "      <td>79.46967</td>\n",
       "      <td>80.39510</td>\n",
       "      <td>77.86652</td>\n",
       "      <td>77.20627</td>\n",
       "      <td>78.33711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118.95958</td>\n",
       "      <td>82.00438</td>\n",
       "      <td>83.84794</td>\n",
       "      <td>80.40048</td>\n",
       "      <td>80.64813</td>\n",
       "      <td>86.74073</td>\n",
       "      <td>90.89855</td>\n",
       "      <td>87.42634</td>\n",
       "      <td>85.88534</td>\n",
       "      <td>86.93229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>82.97925</td>\n",
       "      <td>61.88108</td>\n",
       "      <td>65.54801</td>\n",
       "      <td>59.53692</td>\n",
       "      <td>75.45312</td>\n",
       "      <td>67.36771</td>\n",
       "      <td>61.14406</td>\n",
       "      <td>66.13959</td>\n",
       "      <td>67.73551</td>\n",
       "      <td>67.36372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>76.18434</td>\n",
       "      <td>65.08857</td>\n",
       "      <td>69.81931</td>\n",
       "      <td>70.62222</td>\n",
       "      <td>68.35383</td>\n",
       "      <td>70.47346</td>\n",
       "      <td>67.89549</td>\n",
       "      <td>71.89055</td>\n",
       "      <td>75.20079</td>\n",
       "      <td>75.06871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60.29282</td>\n",
       "      <td>48.66334</td>\n",
       "      <td>59.89032</td>\n",
       "      <td>58.02635</td>\n",
       "      <td>56.43211</td>\n",
       "      <td>55.66685</td>\n",
       "      <td>54.96695</td>\n",
       "      <td>60.79733</td>\n",
       "      <td>64.49536</td>\n",
       "      <td>63.55508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>133.75785</td>\n",
       "      <td>93.39369</td>\n",
       "      <td>99.85986</td>\n",
       "      <td>105.95280</td>\n",
       "      <td>98.82562</td>\n",
       "      <td>105.08918</td>\n",
       "      <td>104.69604</td>\n",
       "      <td>103.96380</td>\n",
       "      <td>104.83067</td>\n",
       "      <td>104.08194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>95.53616</td>\n",
       "      <td>75.76057</td>\n",
       "      <td>87.45220</td>\n",
       "      <td>89.38065</td>\n",
       "      <td>81.48977</td>\n",
       "      <td>84.18368</td>\n",
       "      <td>88.06178</td>\n",
       "      <td>84.99322</td>\n",
       "      <td>84.14878</td>\n",
       "      <td>86.44153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          5       10       15        20       25        30        35  \\\n",
       "0 121.08483 83.22601 84.98515  82.43595 87.58834  95.66110  97.65884   \n",
       "1  76.27096 68.72295 85.44507  91.70347 87.32364  95.86751  96.42208   \n",
       "2  76.40846 62.50184 70.91066  83.65107 75.81232  73.46238  78.72707   \n",
       "3  72.64028 62.72359 71.70770  71.71293 70.69936  79.46967  80.39510   \n",
       "4 118.95958 82.00438 83.84794  80.40048 80.64813  86.74073  90.89855   \n",
       "5  82.97925 61.88108 65.54801  59.53692 75.45312  67.36771  61.14406   \n",
       "6  76.18434 65.08857 69.81931  70.62222 68.35383  70.47346  67.89549   \n",
       "7  60.29282 48.66334 59.89032  58.02635 56.43211  55.66685  54.96695   \n",
       "8 133.75785 93.39369 99.85986 105.95280 98.82562 105.08918 104.69604   \n",
       "9  95.53616 75.76057 87.45220  89.38065 81.48977  84.18368  88.06178   \n",
       "\n",
       "         40        45        50  \n",
       "0  97.40345  96.66076  97.57031  \n",
       "1  96.91586 100.55214 101.13772  \n",
       "2  80.83133  79.28233  79.96562  \n",
       "3  77.86652  77.20627  78.33711  \n",
       "4  87.42634  85.88534  86.93229  \n",
       "5  66.13959  67.73551  67.36372  \n",
       "6  71.89055  75.20079  75.06871  \n",
       "7  60.79733  64.49536  63.55508  \n",
       "8 103.96380 104.83067 104.08194  \n",
       "9  84.99322  84.14878  86.44153  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No need to run the Gurboi optimization if we already have the results stored in a csv!\n",
    "if os.path.exists('gurobi_sse_results.csv'):\n",
    "    gurobi_results_df = pd.read_csv('gurobi_sse_results.csv')\n",
    "else:\n",
    "\n",
    "    for k_fold, indices_dict in k_folds_dict.items():\n",
    "\n",
    "        # Get our training folds and testing folds\n",
    "        X_train_folds, y_train_folds = X_train[indices_dict['train_indices']], y_train[indices_dict['train_indices']]\n",
    "        X_test_fold, y_test_fold = X_train[indices_dict['test_indices']], y_train[indices_dict['test_indices']]\n",
    "\n",
    "        # Now let's try out all of the possible k values\n",
    "        for k in k_options:\n",
    "            optimal_betas = solve_gurobi(X_train_folds,y_train_folds,k)\n",
    "\n",
    "            validation_mse = sse(y_test_fold,predict_y(X_test_fold,optimal_betas))\n",
    "\n",
    "            gurobi_results_df.loc[k_fold,k] = validation_mse  \n",
    "\n",
    "    gurobi_results_df.to_csv('gurobi_sse_results.csv',index=False)\n",
    "\n",
    "gurobi_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total SSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>914.11453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>703.96601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>779.46622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>793.42285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>782.62626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>813.98226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>820.86596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>828.22798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>835.99795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>840.45402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Total SSE\n",
       "5   914.11453\n",
       "10  703.96601\n",
       "15  779.46622\n",
       "20  793.42285\n",
       "25  782.62626\n",
       "30  813.98226\n",
       "35  820.86596\n",
       "40  828.22798\n",
       "45  835.99795\n",
       "50  840.45402"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We aggregate the results of each lambda across all folds by summing each folds SSE to get an \"Aggregate SSE\"\n",
    "total_sse_per_fold_g = gurobi_results_df.sum()\n",
    "pd.DataFrame(total_sse_per_fold_g,columns=['Total SSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the results to see how the total error evolves as the K changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Aggregate SSE Across All Folds')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_sse_per_fold_g.plot(figsize=(10,5),marker='o')\n",
    "plt.title('Total Sum of Squares Error for Fold, by $K$')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Aggregate SSE Across All Folds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we are able to capture a minimum here where k = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best lambda = 10\n"
     ]
    }
   ],
   "source": [
    "# Store the best K for later use\n",
    "best_k = int(total_sse_per_fold_g.sort_values().index[0])\n",
    "print(f'The best lambda = {best_k}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the entire data set using the best lambda calculated above and finally, test on the hold out set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a master df here to store the evaluation metrics for both Gurobi optimization and Lasso. That will make for easy comparison later.\n",
    "best_results = pd.DataFrame(columns=['SSE','MSE','R_Squared'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2022-09-15\n",
      "Using license file C:\\Users\\User\\gurobi.lic\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SSE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R_Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gurobi_Method_Metrics</th>\n",
       "      <td>116.82720</td>\n",
       "      <td>2.33654</td>\n",
       "      <td>0.85867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            SSE     MSE  R_Squared\n",
       "Gurobi_Method_Metrics 116.82720 2.33654    0.85867"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit the model with the best K\n",
    "best_gurobi_betas = solve_gurobi(X_train,y_train,k=best_k)\n",
    "\n",
    "# Predict on hold out set and put the metrics into the best results df\n",
    "gurobi_predictions = predict_y(X_test,best_gurobi_betas)\n",
    "gurobi_sse = sse(y_test,gurobi_predictions)\n",
    "gurobi_mse = mean_squared_error(y_test,gurobi_predictions)\n",
    "gurobi_r_squared = r2_score(y_test,gurobi_predictions)\n",
    "\n",
    "best_results.loc['Gurobi_Method_Metrics'] = [gurobi_sse,gurobi_mse,gurobi_r_squared]\n",
    "best_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking Lambda with scikitlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation is so much easier when scikit does it for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best lambda = 0.07638765995113514\n"
     ]
    }
   ],
   "source": [
    "lasso_model_cv = linear_model.LassoCV(cv=10).fit(X_train_og,y_train_og)\n",
    "best_lambda = lasso_model_cv.alpha_\n",
    "print(f'The best lambda = {best_lambda}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the entire data set using the best lambda calculated above and finally, test on the hold out set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit the best lasso.\n",
    "best_lasso_model = Lasso(best_lambda).fit(X_train_og, y_train_og)\n",
    "\n",
    "# Predict on hold out set and put the metrics into the best results df\n",
    "\n",
    "# We can ignore that column of 1s that was added earlier for the lasso model\n",
    "lasso_predictions = best_lasso_model.predict(X_test[:,1:])\n",
    "lasso_sse = sse(y_test,lasso_predictions)\n",
    "lasso_mse = mean_squared_error(y_test,lasso_predictions)\n",
    "lasso_r_squared = r2_score(y_test,lasso_predictions)\n",
    "\n",
    "best_results.loc['Lasso_Metrics'] = [lasso_sse, lasso_mse, lasso_r_squared]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SSE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R_Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gurobi_Method_Metrics</th>\n",
       "      <td>116.82720</td>\n",
       "      <td>2.33654</td>\n",
       "      <td>0.85867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso_Metrics</th>\n",
       "      <td>117.48174</td>\n",
       "      <td>2.34963</td>\n",
       "      <td>0.85788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            SSE     MSE  R_Squared\n",
       "Gurobi_Method_Metrics 116.82720 2.33654    0.85867\n",
       "Lasso_Metrics         117.48174 2.34963    0.85788"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at how many non-intercept betas are retained with each method. Assuming we get similiar results, we should have a bias towards the least complex model, meaning the one with fewer betas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of non-intercept betas using the lasso method =  17\n",
      "The number of non-intercept betas using the Gurobi Optimization method =  10\n"
     ]
    }
   ],
   "source": [
    "print(f'The number of non-intercept betas using the lasso method =  {(best_lasso_model.coef_ != 0).sum()}')\n",
    "print(f'The number of non-intercept betas using the Gurobi Optimization method =  {(best_gurobi_betas != 0).sum()-1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
